{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from itertools import combinations\n",
    "from itertools import compress\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skmultilearn.adapt import MLkNN\n",
    "from sklearn.metrics import hamming_loss, make_scorer\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "MUSIC_CHOICES = ['classical music', 'pop', 'metal or hardrock', 'hiphop, rap', 'latino', 'alternative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('./resources/responses.csv')\n",
    "raw_data.fillna(0, inplace=True)\n",
    "raw_data.columns = [col.lower() for col in raw_data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_strong_correlations(x):\n",
    "    if abs(x) < 0.1: return 0\n",
    "    return x\n",
    "\n",
    "def convert_to_binary(col):\n",
    "    \"\"\"\n",
    "    Given a two value categorical series, it is converted to its binary representation\n",
    "    \n",
    "    :param Series col: two value categorical series\n",
    "    \n",
    "    :return: a binary series\n",
    "    \"\"\"\n",
    "    \n",
    "    unique_val = col.unique()[0]\n",
    "    copy = col.copy()\n",
    "    for index, row in enumerate(copy):\n",
    "        if row == unique_val:\n",
    "            copy[index] = 0\n",
    "        else:\n",
    "            copy[index] = 1\n",
    "    return copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# getting all the categorical columns \n",
    "categorical_data = raw_data[list(set(raw_data.columns) - set(raw_data._get_numeric_data().columns))]\n",
    "categorical_data.drop(['gender'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the binary categorical columns to 0s and 1s\n",
    "# this is done to avoid linearly dependent columns \n",
    "binary_data = categorical_data[['left - right handed', 'only child']]\n",
    "for col in binary_data:\n",
    "    categorical_data.loc[:, col] = convert_to_binary(binary_data.loc[:, col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# one hot encoding \n",
    "categorical_data = pd.get_dummies(categorical_data, prefix_sep='_', drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_heatmap(df, music_choices=MUSIC_CHOICES, threshold=0.04, only_strong_corr=True):\n",
    "    \"\"\"\n",
    "    Given a dataframe a heatmap is returned with only values above the \n",
    "    threhold being displayed\n",
    "    \n",
    "    :param DataFrame df: A numerical dataframe\n",
    "    :param list music_choices: The genres of music that one would like displayed\n",
    "    :param float threshold: The average value required for a row to be displayed\n",
    "    \n",
    "    :return: a sns heatmap\n",
    "    \"\"\"\n",
    "    # corr is a square correlation matrix (n * n), where n is the number of features\n",
    "    if only_strong_corr:\n",
    "        # only_corrleations() makes cell values 0 if their correlation is less than 0.1\n",
    "        df = df._get_numeric_data().corr().applymap(only_strong_correlations)\n",
    "    else:\n",
    "        df = df._get_numeric_data().corr()\n",
    "        \n",
    "    # picking only the music columns \n",
    "    df = df[music_choices]\n",
    "    # excluding all music rows \n",
    "    df = df.loc[set(df.index) - set(music_choices)]\n",
    "\n",
    "    # only rows above a certain threshold are kept\n",
    "    # 0.04 was chosen as the threshold since it \n",
    "    # is slightly higher than the avg of the row avgs, which was 0.039\n",
    "\n",
    "    # avg is the average of all the rows \n",
    "    avg = 0\n",
    "    initial_len = len(df)\n",
    "    for index, row in df.iterrows():\n",
    "        add = 0\n",
    "        for col in row: \n",
    "            add += abs(col)\n",
    "        avg += add/len(row)\n",
    "        if add/len(row) < threshold:\n",
    "            df.drop(index, axis=0, inplace=True)\n",
    "    print(avg/initial_len)\n",
    "    \n",
    "    plt.figure(figsize=(25,20))\n",
    "    return sns.heatmap(df, cmap= sns.color_palette(\"RdBu_r\", 7), annot=True, linewidth=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "for line in open('./resources/reduced_correlations.txt'):\n",
    "    questions.append(line.lower().rstrip())\n",
    "question_data = raw_data[questions]\n",
    "\n",
    "# generate_heatmap(question_data.join(music_data), only_strong_corr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_music_labels(col):\n",
    "    \"\"\"\n",
    "    Concludes an individual likes a genere of music if they rated it greater or equal to four.\n",
    "    \n",
    "    :param Series col: a series of integers \n",
    "    :return: a series of bools\n",
    "    \n",
    "    \"\"\"\n",
    "    return col.apply(lambda x: True if x >= 4 else False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "music_data = raw_data[MUSIC_CHOICES]\n",
    "for col in music_data:\n",
    "    music_data[col] = create_music_labels(music_data[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# gender is binary so we convert that prior to OHE (One Hot Encoding)\n",
    "question_data.loc[:,['gender']] = convert_to_binary(question_data['gender'])\n",
    "# OHE\n",
    "question_data = pd.get_dummies(question_data, drop_first=True).astype(int)\n",
    "question_data = question_data.rename(columns={'gender_1': 'gender'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(question_data, music_data, grid_search, k=None, s=None):\n",
    "    if grid_search:\n",
    "        parameters = {'k': range(2,17,2), 's': [0.5, 0.7, 1.0]}\n",
    "        score = make_scorer(hamming_loss)   \n",
    "        clf = GridSearchCV(MLkNN(), parameters, scoring=score, n_jobs=-1, cv=5)\n",
    "        clf.fit(question_data.values, music_data.values)\n",
    "        return clf.best_params_, clf.best_score_\n",
    "    else:\n",
    "        clf = MLkNN(k=k, s=s)\n",
    "        clf.fit(question_data.values, music_data.values)\n",
    "        return clf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of choices of music people like\n",
    "d = {}\n",
    "for row in music_data.values.tolist():\n",
    "    row = tuple(row)\n",
    "    if row in d.keys():\n",
    "        d[row] += 1\n",
    "    else:\n",
    "        d[row] = 1\n",
    "\n",
    "# showing only the top 10 multi-label combinations\n",
    "highest_counts = sorted(d.values(), reverse=True)[:10]\n",
    "\n",
    "for category, value in d.items():\n",
    "    if value in highest_counts:\n",
    "        print(list(compress(list(music_data.columns), list(category))), value)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "clf = OneVsRestClassifier(XGBClassifier(n_jobs=-1, max_depth=4))\n",
    "\n",
    "# You may need to use MultiLabelBinarizer to encode your variables from arrays [[x, y, z]] to a multilabel \n",
    "# format before training.\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(music_data)\n",
    "\n",
    "clf.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_features(question_data, music_data):\n",
    "    \"\"\"\n",
    "    Finds the best ten features to use for a given dataset\n",
    "    Utilizes GridSearchCV to figure out the best hyperparamter values. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    best_score = 100\n",
    "    best_params = None\n",
    "    best_features = None\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(question_data, music_data, test_size=0.05, random_state=42)\n",
    "\n",
    "    feature_set = set(X_train.columns)\n",
    "    feature_set.remove('gender_1')\n",
    "\n",
    "    for index, comb in enumerate(list(combinations(feature_set, 9))):\n",
    "        comb = list(comb + ('gender_1',))\n",
    "        params, score = create_model(X_train[comb], y_train, True)\n",
    "        # since we are using hemming score, a lower score is better\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_params = params\n",
    "            best_features = comb\n",
    "        print(index)\n",
    "    return best_score, best_params, best_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, params, features = find_best_features(question_data[reduced_features], music_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, params, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the actual model to be used\n",
    "with open('./resources/final_model_values.json') as file:\n",
    "    json_file = json.load(file)\n",
    "features = json_file['features']\n",
    "clf = create_model(question_data[features], music_data, False, 4, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = np.asarray([[2, 2, 4, 1, 3, 5, 0, 4, 4, 1]])\n",
    "\n",
    "genres = list(compress(list(music_data.columns), clf.predict(response).toarray()[0]))\n",
    "proba = clf.predict_proba(response).toarray()[0]\n",
    "print(genres, proba)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
