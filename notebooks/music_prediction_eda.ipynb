{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from itertools import combinations\n",
    "from itertools import compress\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skmultilearn.adapt import MLkNN\n",
    "from sklearn.metrics import hamming_loss, make_scorer, jaccard_score, multilabel_confusion_matrix, zero_one_loss, roc_auc_score\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "\n",
    "MUSIC_CHOICES = ['classical music', 'pop', 'metal or hardrock', 'hiphop, rap', 'latino', 'alternative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('./resources/responses.csv')\n",
    "raw_data.columns = [col.lower() for col in raw_data.columns]\n",
    "raw_data.dropna(subset=['gender'], inplace=True)\n",
    "raw_data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_strong_correlations(x):\n",
    "    if abs(x) < 0.1: return 0\n",
    "    return x\n",
    "\n",
    "def convert_to_binary(col):\n",
    "    \"\"\"\n",
    "    Given a two value categorical series, it is converted to its binary representation\n",
    "    \n",
    "    :param Series col: two value categorical series\n",
    "    \n",
    "    :return: a binary series\n",
    "    \"\"\"\n",
    "    \n",
    "    return pd.get_dummies(col, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# getting all the categorical columns \n",
    "categorical_data = raw_data[list(set(raw_data.columns) - set(raw_data._get_numeric_data().columns))]\n",
    "categorical_data.drop(['gender'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the binary categorical columns to 0s and 1s\n",
    "# this is done to avoid linearly dependent columns \n",
    "binary_data = categorical_data[['left - right handed', 'only child']]\n",
    "for col in binary_data:\n",
    "    categorical_data.loc[:, col] = convert_to_binary(binary_data.loc[:, col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# one hot encoding \n",
    "categorical_data = pd.get_dummies(categorical_data, prefix_sep='_', drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_heatmap(df, music_choices=MUSIC_CHOICES, threshold=0.04, only_strong_corr=True):\n",
    "    \"\"\"\n",
    "    Given a dataframe a heatmap is returned with only values above the \n",
    "    threhold being displayed\n",
    "    \n",
    "    :param DataFrame df: A numerical dataframe\n",
    "    :param list music_choices: The genres of music that one would like displayed\n",
    "    :param float threshold: The average value required for a row to be displayed\n",
    "    \n",
    "    :return: a sns heatmap\n",
    "    \"\"\"\n",
    "    # corr is a square correlation matrix (n * n), where n is the number of features\n",
    "    if only_strong_corr:\n",
    "        # only_corrleations() makes cell values 0 if their correlation is less than 0.1\n",
    "        df = df._get_numeric_data().corr().applymap(only_strong_correlations)\n",
    "    else:\n",
    "        df = df._get_numeric_data().corr()\n",
    "        \n",
    "    # picking only the music columns \n",
    "    df = df[music_choices]\n",
    "    # excluding all music rows \n",
    "    df = df.loc[set(df.index) - set(music_choices)]\n",
    "\n",
    "    # only rows above a certain threshold are kept\n",
    "    # 0.04 was chosen as the threshold since it \n",
    "    # is slightly higher than the avg of the row avgs, which was 0.039\n",
    "\n",
    "    # avg is the average of all the rows \n",
    "    avg = 0\n",
    "    initial_len = len(df)\n",
    "    for index, row in df.iterrows():\n",
    "        add = 0\n",
    "        for col in row: \n",
    "            add += abs(col)\n",
    "        avg += add/len(row)\n",
    "        if add/len(row) < threshold:\n",
    "            df.drop(index, axis=0, inplace=True)\n",
    "    print(avg/initial_len)\n",
    "    \n",
    "    plt.figure(figsize=(25,20))\n",
    "    return sns.heatmap(df, cmap= sns.color_palette(\"RdBu_r\", 7), annot=True, linewidth=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "for line in open('./resources/reduced_correlations.txt'):\n",
    "    questions.append(line.lower().rstrip())\n",
    "question_data = raw_data[questions]\n",
    "\n",
    "# generate_heatmap(question_data.join(music_data), only_strong_corr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_music_labels(col):\n",
    "    \"\"\"\n",
    "    Concludes an individual likes a genere of music if they rated it greater or equal to four.\n",
    "    \n",
    "    :param Series col: a series of integers \n",
    "    :return: a series of bools\n",
    "    \n",
    "    \"\"\"\n",
    "    return col.apply(lambda x: True if x >= 4 else False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "music_data = raw_data[MUSIC_CHOICES]\n",
    "for col in music_data:\n",
    "    music_data[col] = create_music_labels(music_data[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gender is binary so we convert that prior to OHE (One Hot Encoding)\n",
    "question_data.gender = question_data.gender.apply(lambda row: 1 if 'female' in row else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# OHE\n",
    "question_data = pd.get_dummies(question_data, drop_first=True).astype(int)\n",
    "question_data = question_data.rename(columns={'gender_1': 'gender'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlknn_model(question_data, music_data, grid_search, k=None, s=None):\n",
    "    if grid_search:\n",
    "        parameters = {'k': range(2,17,2), 's': [0.5, 0.7, 1.0]}\n",
    "        score = make_scorer(hamming_loss)   \n",
    "        clf = GridSearchCV(MLkNN(), parameters, scoring=score, n_jobs=-1, cv=5)\n",
    "        clf.fit(question_data.values, music_data.values)\n",
    "        return clf.best_params_, clf.best_score_\n",
    "    else:\n",
    "        clf = MLkNN(k=k, s=s)\n",
    "        clf.fit(question_data.values, music_data.values)\n",
    "        return clf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of choices of music people like\n",
    "d = {}\n",
    "for row in music_data.values.tolist():\n",
    "    row = tuple(row)\n",
    "    if row in d.keys():\n",
    "        d[row] += 1\n",
    "    else:\n",
    "        d[row] = 1\n",
    "\n",
    "# showing only the top 10 multi-label combinations\n",
    "highest_counts = sorted(d.values(), reverse=True)[:10]\n",
    "\n",
    "for category, value in d.items():\n",
    "    if value in highest_counts:\n",
    "        print(list(compress(list(music_data.columns), list(category))), value)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_features(question_data, music_data):\n",
    "    \"\"\"\n",
    "    Finds the best ten features to use for a given dataset\n",
    "    Utilizes GridSearchCV to figure out the best hyperparamter values. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    best_score = 100\n",
    "    best_params = None\n",
    "    best_features = None\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(question_data, music_data, test_size=0.05, random_state=42)\n",
    "\n",
    "    feature_set = set(X_train.columns)\n",
    "    feature_set.remove('gender_1')\n",
    "\n",
    "    for index, comb in enumerate(list(combinations(feature_set, 9))):\n",
    "        comb = list(comb + ('gender_1',))\n",
    "        params, score = create_model(X_train[comb], y_train, True)\n",
    "        # since we are using hemming score, a lower score is better\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_params = params\n",
    "            best_features = comb\n",
    "        print(index)\n",
    "    return best_score, best_params, best_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this cell only if one would like to call find_best_features() which is a timeconsuming\n",
    "# function call\n",
    "\n",
    "# score, params, features = find_best_features(question_data[reduced_features], music_data)\n",
    "# score, params, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the actual model to be used\n",
    "with open('./resources/final_mlknn_model_values.json') as file:\n",
    "    json_file = json.load(file)\n",
    "features = json_file['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(question_data[features], music_data, test_size=0.10, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparamters = json_file['hyperparameters']\n",
    "mlknn_clf = create_mlknn_model(X_train, y_train, False, hyperparamters['k'], hyperparamters['s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Note: The Grid Search was done on a few parameters at a time\n",
    "1. Increased the learning rate to 0.15 and kept number_estimators = [100, 200, 500, 1000]\n",
    "2. Tune max_depth and min_child_weight\n",
    "3. Tune gamma\n",
    "4. Tune subsample and colsample_bytree\n",
    "5. Tuning Regularization Parameters\n",
    "6. Tune learning rate and number of estimators \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "model = XGBClassifier(silent=False,\n",
    "                      objective='multi:softmax',\n",
    "                      num_class=6,\n",
    "                      eval_metric = \"auc\", \n",
    "                      seed=27, \n",
    "                      early_stopping_rounds=50, \n",
    "                      max_depth=2, \n",
    "                      gamma=0.3, \n",
    "                      min_child_weight=5, \n",
    "                      subsample=0.7, \n",
    "                      colsample_bytree=0.80, \n",
    "                      reg_alpha=0.005,\n",
    "                      learning_rate=0.1, \n",
    "                      n_estimators=200,\n",
    "                      n_jobs=-1)\n",
    "\n",
    "clf = OneVsRestClassifier(model)\n",
    "\n",
    "fit_params={\n",
    "    \"early_stopping_rounds\": 42, \n",
    "    \"eval_metric\" : [\"auc\",\"error\"], \n",
    "    \"eval_set\" : [[X_train, y_train]]\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    \"estimator__n_estimators\" : [100, 200, 500, 1000, 2000, 5000, 7000],\n",
    "    \"estimator__learning_rate\": [0.01, 0.03, 0.05, 0.07, 0.1]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch = GridSearchCV(clf, param_grid, verbose=True, cv=4, n_jobs=-1, scoring=make_scorer(roc_auc_score))\n",
    "gs_model = gridsearch.fit(question_data[features], music_data)\n",
    "gs_model.best_estimator_, gs_model.best_score_\n",
    "results = pd.DataFrame(gs_model.cv_results_)\n",
    "results.sort_values(by=['rank_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_xgb_model = XGBClassifier(silent=False,\n",
    "                                objective='multi:softmax',\n",
    "                                num_class=6,\n",
    "                                eval_metric = \"auc\", \n",
    "                                seed=27, \n",
    "                                early_stopping_rounds=50, \n",
    "                                max_depth=2, \n",
    "                                gamma=0.3, \n",
    "                                min_child_weight=5, \n",
    "                                subsample=0.7, \n",
    "                                colsample_bytree=0.80, \n",
    "                                reg_alpha=0.005,\n",
    "                                learning_rate=0.03, \n",
    "                                n_estimators=500, \n",
    "                                n_jobs=-1)\n",
    "xgb_clf = OneVsRestClassifier(model, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_vals = {}\n",
    "final_vals['features'] = features\n",
    "\n",
    "xgb_params = xgb_clf.get_params()\n",
    "keys = list(xgb_params.keys())\n",
    "keys.pop()\n",
    "keys.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb_hyperparameters = {key:xgb_params[key] for key in keys}\n",
    "xgb_hyperparameters    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_vals['hyperparameters'] = xgb_hyperparameters\n",
    "final_vals['genres'] = list(music_data.columns)\n",
    "with open('./resources/final_xgboost_model_values.json', 'w') as f:\n",
    "    json.dump(final_vals, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(clf, open('./model/xgboost_model.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, mlknn_clf.predict(X_test.values).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, xgb_clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = OneVsRestClassifier(LogisticRegression(max_iter=500), n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, log_reg.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.predict([[2, 4, 3, 4, 3, 2, 2, 4, 4, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.coef_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
